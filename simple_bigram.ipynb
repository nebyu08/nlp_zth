{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Jhr0VLYP0UDOCFiJjvnkxmVBbIcjUU4P",
      "authorship_tag": "ABX9TyMNIuB6gFcubZBJb0lK9VK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nebyu08/nlp_zth/blob/main/simple_bigram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IqvD0gDoDQWp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=open(\"/content/input.txt\").read()\n",
        "chars=sorted(list(set(text)))\n",
        "vocab_size=len(chars)"
      ],
      "metadata": {
        "id": "y_Osh1l7DbIc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi={s:i for i,s in enumerate(chars)}\n",
        "itos={i:s for s,i in stoi.items()}\n",
        "encode=lambda s:[stoi[i] for i in s] # ecodes the string into integers\n",
        "decode=lambda n:\"\".join([itos[i] for i in n]) #decode the number into strings"
      ],
      "metadata": {
        "id": "1FhLHAppEBSo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode(\"hello there friend\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs1RkGQZEPMo",
        "outputId": "0937347d-3441-4495-8882-ce29f15fec84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43, 1, 44, 56, 47, 43, 52, 42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode([46, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43, 1, 44, 56, 47, 43, 52, 42]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1CbokJjNIzI",
        "outputId": "7ba11d77-76ae-4ed2-8f85-cdd6ab09ca99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello there friend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.tensor(encode(text),dtype=torch.long)\n",
        "print(data.type,data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOE826s4NNnC",
        "outputId": "5cf20be8-7aa0-42af-9361-2a2f868ff425"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method type of Tensor object at 0x7b97cc3630b0> torch.Size([1115394])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets split our data into training and validating set\n",
        "n=int(len(data)*0.9)\n",
        "train_data=data[:n]\n",
        "valid_data=data[n:]"
      ],
      "metadata": {
        "id": "qzLISrcFSb38"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size=8\n",
        "x=train_data[:block_size]\n",
        "y=train_data[1:block_size+1]\n",
        "\n",
        "for i in range(block_size):\n",
        "  context=x[:i+1]\n",
        "  target=y[i]\n",
        "  print(\"context |\",context,\" target|\",target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhye0ueRTVzf",
        "outputId": "67abedb6-7ca2-4761-cfb8-4ef93d2f9387"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context | tensor([18])  target| tensor(47)\n",
            "context | tensor([18, 47])  target| tensor(56)\n",
            "context | tensor([18, 47, 56])  target| tensor(57)\n",
            "context | tensor([18, 47, 56, 57])  target| tensor(58)\n",
            "context | tensor([18, 47, 56, 57, 58])  target| tensor(1)\n",
            "context | tensor([18, 47, 56, 57, 58,  1])  target| tensor(15)\n",
            "context | tensor([18, 47, 56, 57, 58,  1, 15])  target| tensor(47)\n",
            "context | tensor([18, 47, 56, 57, 58,  1, 15, 47])  target| tensor(58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets batchify our code\n",
        "torch.manual_seed(1337)\n",
        "batch_size=4\n",
        "block_size=8\n",
        "def get_batch(split):\n",
        "  #this creates x batch and y batch\n",
        "  data= train_data if split==\"train\" else valid_data\n",
        "  xi=torch.randint(len(data)-block_size,(batch_size,))\n",
        "  xb=torch.stack([data[i:i+block_size] for i in xi])\n",
        "  yb=torch.stack([data[i+1:i+block_size+1] for i in xi])\n",
        "  return xb,yb"
      ],
      "metadata": {
        "id": "tu9Fj-egVphO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNGcn6JwVXWz",
        "outputId": "08742154-e97f-41bc-bec5-b5b6966050ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "----\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets make a bigam\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as f\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self,vocab_size):   # super cool inheritance is going on here\n",
        "    super().__init__()\n",
        "    self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n",
        "\n",
        "  def forward(self,idx,target=None):\n",
        "    logits=self.token_embedding_table(idx) #the shape is batch size,context size,vocab size\n",
        "    if target is None:\n",
        "      loss=None\n",
        "    else:\n",
        "      B,T,C=logits.shape\n",
        "      logits=logits.view(B*T,C)\n",
        "      target=target.view(B*T)  #i could say -1 to make it flatten\n",
        "      loss=F.cross_entropy(logits,target)\n",
        "    return logits,loss\n",
        "\n",
        "  def generate(self,idx,max_tokens):\n",
        "    for _ in range(max_tokens):\n",
        "      logits,loss=self(idx) # need only the logits\n",
        "      logits=logits[:,-1,:] #make the probability distribution only\n",
        "      probs=torch.softmax(logits,dim=1)  #i have to make this one probability distribution\n",
        "      idx_next=torch.multinomial(probs,num_samples=1)\n",
        "      idx=torch.cat((idx,idx_next),dim=1)\n",
        "    return idx\n",
        ""
      ],
      "metadata": {
        "id": "fmBBwQB5c6bM"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m=BigramLanguageModel(vocab_size)\n",
        "logits,loss=m(xb,yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "print(decode(m.generate(idx=torch.zeros(1,1,dtype=torch.long),max_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhx-E3scg0v2",
        "outputId": "a41d6cd7-b4e1-47d5-e3c0-3d466f967f17"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets try to optimize the code\n",
        "optimizer=torch.optim.AdamW(m.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "mCHYcYWafdaJ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(1500):\n",
        "  xb,yb=get_batch(\"train\")\n",
        "  logits,loss=m(xb,yb)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  optimizer.step()\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjQIxxLfxrg_",
        "outputId": "55171c08-078e-4d7f-c703-20e55ddb3636"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.832476854324341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx=torch.zeros(1,1,dtype=torch.long),max_tokens=400)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "runt0wlVyOUD",
        "outputId": "e56e4748-2cd8-4db6-8c14-0c6e54885055"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HESCESCooourd har:\n",
            "\n",
            "Thed, d'd.\n",
            "\n",
            "Whar t o ore pus t ll s, oore tewe t\n",
            "SCinou's, d ay bor tsth vespul f ard.\n",
            "Whar hadu,\n",
            "O:\n",
            "\n",
            "Vin arsu, bucoute thinthays t ad.\n",
            "Lethelt ale t ar ous tens! ore pr bu,\n",
            "VILou,\n",
            "\n",
            "Nor seanot t:\n",
            "Whayoo altheeming, halallo ryoullal l O,\n",
            "LIELIf t pris, ar d t oul an t an avinimauladextuk ve lmy, ounthefe ad.\n",
            "Thalay y thay ou awank digh t\n",
            "O, oor d Be t ar O, tsoutn Yoor myoreway.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QecJ0u1ZzOAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}